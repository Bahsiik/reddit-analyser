{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T09:14:19.546839Z",
     "start_time": "2025-06-17T09:14:19.542931Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data from csv file\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/chatgpt-reddit-comments.csv')\n",
    "\n",
    "# print the first 5 rows\n",
    "# print(df.head())\n",
    "\n",
    "# print the last 5 rows\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd5f144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class TextCleaner:\n",
    "\t\"\"\"\n",
    "\tClass for cleaning and preprocessing text data with multiple processing steps.\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tdef __init__(self):\n",
    "\t\tpass\n",
    "\t\n",
    "\tdef remove_html(self, text):\n",
    "\t\t\"\"\"Remove HTML tags from text.\"\"\"\n",
    "\t\tif not isinstance(text, str):\n",
    "\t\t\treturn \"\"\n",
    "\t\treturn BeautifulSoup(text, \"html.parser\").get_text()\n",
    "\t\n",
    "\tdef convert_to_lowercase(self, text):\n",
    "\t\t\"\"\"Convert text to lowercase.\"\"\"\n",
    "\t\tif not isinstance(text, str):\n",
    "\t\t\treturn \"\"\n",
    "\t\treturn text.lower()\n",
    "\t\n",
    "\tdef remove_urls(self, text):\n",
    "\t\t\"\"\"Remove URLs from text.\"\"\"\n",
    "\t\tif not isinstance(text, str):\n",
    "\t\t\treturn \"\"\n",
    "\t\treturn re.sub(r\"http\\S+\", \"\", text)\n",
    "\t\n",
    "\tdef remove_mentions_hashtags(self, text):\n",
    "\t\t\"\"\"Remove mentions (@username) and hashtags (#hashtag) from text.\"\"\"\n",
    "\t\tif not isinstance(text, str):\n",
    "\t\t\treturn \"\"\n",
    "\t\treturn re.sub(r\"@\\w+|#\\w+\", \"\", text)\n",
    "\t\n",
    "\tdef remove_punctuation(self, text):\n",
    "\t\t\"\"\"Remove punctuation from text.\"\"\"\n",
    "\t\tif not isinstance(text, str):\n",
    "\t\t\treturn \"\"\n",
    "\t\treturn re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "\t\n",
    "\tdef remove_digits(self, text):\n",
    "\t\t\"\"\"Remove digits from text.\"\"\"\n",
    "\t\tif not isinstance(text, str):\n",
    "\t\t\treturn \"\"\n",
    "\t\treturn re.sub(r\"\\d+\", \"\", text)\n",
    "\t\n",
    "\tdef normalize_whitespace(self, text):\n",
    "\t\t\"\"\"Normalize whitespace in text.\"\"\"\n",
    "\t\tif not isinstance(text, str):\n",
    "\t\t\treturn \"\"\n",
    "\t\treturn re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\t\n",
    "\tdef clean_text(self, text):\n",
    "\t\t\"\"\"\n",
    "\t\tApply all cleaning steps to the text.\n",
    "\t\t\n",
    "\t\tArgs:\n",
    "\t\t\ttext (str): The text to clean\n",
    "\t\t\t\n",
    "\t\tReturns:\n",
    "\t\t\tstr: The cleaned text\n",
    "\t\t\"\"\"\n",
    "\t\tif not isinstance(text, str):\n",
    "\t\t\treturn \"\"\n",
    "\t\t\n",
    "\t\t# Apply all cleaning steps in sequence\n",
    "\t\ttext = self.remove_html(text)\n",
    "\t\ttext = self.convert_to_lowercase(text)\n",
    "\t\ttext = self.remove_urls(text)\n",
    "\t\ttext = self.remove_mentions_hashtags(text)\n",
    "\t\ttext = self.remove_punctuation(text)\n",
    "\t\ttext = self.remove_digits(text)\n",
    "\t\ttext = self.normalize_whitespace(text)\n",
    "\t\t\n",
    "\t\treturn text\n",
    "\n",
    "# Create an instance for backward compatibility\n",
    "cleaner = TextCleaner()\n",
    "\n",
    "def clean_text(text):\n",
    "\t\"\"\"\n",
    "\tLegacy function for backward compatibility.\n",
    "\t\"\"\"\n",
    "\treturn cleaner.clean_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eef9fd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original:\n",
      "'\\n<p>Hello @user123! Check out this link: https://example.com/test #AI #ChatGPT</p>\\nThis has NUMBERS 123 and punctuation!!! \\n   Multiple    spaces   everywhere.\\n'\n",
      "\n",
      "==================================================\n",
      "\n",
      "1. Suppression HTML: '\\nHello @user123! Check out this link: https://example.com/test #AI #ChatGPT\\nThis has NUMBERS 123 and punctuation!!! \\n   Multiple    spaces   everywhere.\\n'\n",
      "2. Conversion minuscules: '\\nhello @user123! check out this link: https://example.com/test #ai #chatgpt\\nthis has numbers 123 and punctuation!!! \\n   multiple    spaces   everywhere.\\n'\n",
      "3. Suppression URLs: \"Visitez  pour plus d'infos\"\n",
      "4. Suppression mentions/hashtags: 'Salut  '\n",
      "5. Suppression ponctuation: 'Hello world'\n",
      "6. Suppression chiffres: \"J'ai  ans en \"\n",
      "7. Normalisation espaces: 'espaces multiples'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Nettoyage complet:\n",
      "'hello check out this link this has numbers and punctuation multiple spaces everywhere'\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test de la classe NettoyeurTexte\n",
    "cleaner = TextCleaner()\n",
    "\n",
    "# Exemple de texte à nettoyer\n",
    "texte_test = \"\"\"\n",
    "<p>Hello @user123! Check out this link: https://example.com/test #AI #ChatGPT</p>\n",
    "This has NUMBERS 123 and punctuation!!! \n",
    "   Multiple    spaces   everywhere.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Texte original:\")\n",
    "print(repr(texte_test))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Test de chaque étape individuellement\n",
    "print(\"1. Suppression HTML:\", repr(cleaner.remove_html(texte_test)))\n",
    "print(\"2. Conversion minuscules:\", repr(cleaner.convert_to_lowercase(cleaner.remove_html(texte_test))))\n",
    "print(\"3. Suppression URLs:\", repr(cleaner.remove_urls(\"Visitez https://example.com pour plus d'infos\")))\n",
    "print(\"4. Suppression mentions/hashtags:\", repr(cleaner.remove_mentions_hashtags(\"Salut @user #test\")))\n",
    "print(\"5. Suppression ponctuation:\", repr(cleaner.remove_punctuation(\"Hello, world!!!\")))\n",
    "print(\"6. Suppression chiffres:\", repr(cleaner.remove_digits(\"J'ai 25 ans en 2023\")))\n",
    "print(\"7. Normalisation espaces:\", repr(cleaner.normalize_whitespace(\"   espaces    multiples   \")))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Test du nettoyage complet\n",
    "print(\"Nettoyage complet:\")\n",
    "resultat_complet = cleaner.clean_text(texte_test)\n",
    "print(repr(resultat_complet))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
