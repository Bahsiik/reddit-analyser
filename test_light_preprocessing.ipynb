{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test du Pipeline Light de Preprocessing pour l'Analyse de Sentiment\n",
        "\n",
        "Ce notebook teste la version \"light\" complÃ¨te du pipeline de preprocessing optimisÃ©e pour prÃ©server les indicateurs Ã©motionnels importants pour l'analyse de sentiment.\n",
        "\n",
        "## ğŸ“‹ Pipeline testÃ© :\n",
        "1. **Nettoyage** (`TextCleaner` light)\n",
        "2. **Tokenisation** (`TextTokenizer` amÃ©liorÃ©)\n",
        "3. **Retrait des stopwords** (`StopwordRemover` light) \n",
        "4. **Lemmatisation** (`TextLemmatizer` light)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports des classes light\n",
        "import sys\n",
        "\n",
        "from preprocessing.light.text_cleaner_light import TextCleaner\n",
        "from preprocessing.text_tokenizer import TextTokenizer\n",
        "from preprocessing.light.stopword_remover_light import StopwordRemover\n",
        "from preprocessing.light.text_lemmatizer_light import TextLemmatizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration NLTK\n",
        "import nltk\n",
        "import os\n",
        "\n",
        "nltk_dir = 'nltk_data'\n",
        "nltk.data.path.append(os.path.abspath(nltk_dir))\n",
        "\n",
        "# DÃ©commentez si premier run\n",
        "# nltk.download('punkt_tab', download_dir=nltk_dir)\n",
        "# nltk.download('stopwords', download_dir=nltk_dir)\n",
        "# nltk.download('wordnet', download_dir=nltk_dir)\n",
        "# nltk.download('omw-1.4', download_dir=nltk_dir)\n",
        "# nltk.download('averaged_perceptron_tagger_eng', download_dir=nltk_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Toutes les classes sont initialisÃ©es !\n"
          ]
        }
      ],
      "source": [
        "# Initialisation des classes\n",
        "text_cleaner = TextCleaner()\n",
        "tokenizer = TextTokenizer(nltk_dir=nltk_dir)\n",
        "stopword_remover = StopwordRemover()\n",
        "lemmatizer = TextLemmatizer(nltk_dir=nltk_dir)\n",
        "\n",
        "print(\"âœ… Toutes les classes sont initialisÃ©es !\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ§ª Exemples de Test VariÃ©s\n",
        "\n",
        "Nous allons tester diffÃ©rents types de textes pour voir comment le pipeline light prÃ©serve les Ã©lÃ©ments Ã©motionnels :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“ 7 exemples de test prÃ©parÃ©s\n"
          ]
        }
      ],
      "source": [
        "# Exemples de textes avec diffÃ©rents dÃ©fis pour l'analyse de sentiment\n",
        "test_texts = [\n",
        "\t\"I'm soooo HAPPY!!! This is absolutely AMAZING ğŸ˜ Much better than before!!!\",\n",
        "\t\n",
        "\t\"Can't believe how terrible this is... I'm extremely disappointed ğŸ˜ Worst experience EVER!\",\n",
        "\t\n",
        "\t\"<p>This ChatGPT update is @amazing #AI https://example.com BUT I don't think it's perfect yet...</p>\",\n",
        "\t\n",
        "\t\"Nooooo way! This is incredible!!! I absolutely looove it ğŸ’• 10/10 would recommend!\",\n",
        "\t\n",
        "\t\"It's quite good, but I've seen better products in 2024. Not bad though, just not outstanding.\",\n",
        "\t\n",
        "\t\"OMG this is HORRIBLE!!! Won't buy again, totally disgusting and revolting ğŸ¤®\",\n",
        "\t\n",
        "\t\"I really, really love this! It's so much more efficient than the old version. Fantastic work!\"\n",
        "]\n",
        "\n",
        "print(f\"ğŸ“ {len(test_texts)} exemples de test prÃ©parÃ©s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”„ Fonction de Pipeline ComplÃ¨te\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_text_light(text):\n",
        "\t\"\"\"\n",
        "\tApplique le pipeline light complet sur un texte.\n",
        "\t\n",
        "\tArgs:\n",
        "\t\ttext (str): Texte Ã  traiter\n",
        "\t\t\n",
        "\tReturns:\n",
        "\t\tdict: RÃ©sultats de chaque Ã©tape\n",
        "\t\"\"\"\n",
        "\tresults = {\n",
        "\t\t'original': text,\n",
        "\t\t'cleaned': '',\n",
        "\t\t'tokens': [],\n",
        "\t\t'without_stopwords': [],\n",
        "\t\t'lemmatized': []\n",
        "\t}\n",
        "\t\n",
        "\t# Ã‰tape 1: Nettoyage\n",
        "\tresults['cleaned'] = text_cleaner.clean_text(text)\n",
        "\t\n",
        "\t# Ã‰tape 2: Tokenisation\n",
        "\tresults['tokens'] = tokenizer.tokenize(results['cleaned'])\n",
        "\t\n",
        "\t# Ã‰tape 3: Retrait des stopwords\n",
        "\tresults['without_stopwords'] = stopword_remover.remove_stopwords(results['tokens'])\n",
        "\t\n",
        "\t# Ã‰tape 4: Lemmatisation\n",
        "\tresults['lemmatized'] = lemmatizer.lemmatize(results['without_stopwords'], conservative_mode=True)\n",
        "\t\n",
        "\treturn results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š Test et Analyse des RÃ©sultats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "ğŸ“ EXEMPLE 1\n",
            "================================================================================\n",
            "ğŸ”¸ Original:\n",
            "   I'm soooo HAPPY!!! This is absolutely AMAZING ğŸ˜ Much better than before!!!\n",
            "\n",
            "ğŸ§¹ NettoyÃ©:\n",
            "   'i'm soooo happy!!! this is absolutely AMAZING ğŸ˜ much better than before!!!'\n",
            "\n",
            "ğŸ”¤ Tokens (18) :\n",
            "   [\"i'm\", 'soo', 'happy', '!', '!', '!', 'this', 'is', 'absolutely', 'AMAZING', 'ğŸ˜', 'much', 'better', 'than', 'before', '!', '!', '!']\n",
            "\n",
            "ğŸš« Sans stopwords (13) :\n",
            "   ['soo', 'happy', '!', '!', '!', 'absolutely', 'AMAZING', 'ğŸ˜', 'much', 'better', '!', '!', '!']\n",
            "\n",
            "ğŸ”„ LemmatisÃ© (13) :\n",
            "   ['soo', 'hapy', '!', '!', '!', 'absolutely', 'AMAZING', 'ğŸ˜', 'much', 'better', '!', '!', '!']\n",
            "\n",
            "================================================================================\n",
            "ğŸ“ EXEMPLE 2\n",
            "================================================================================\n",
            "ğŸ”¸ Original:\n",
            "   Can't believe how terrible this is... I'm extremely disappointed ğŸ˜ Worst experience EVER!\n",
            "\n",
            "ğŸ§¹ NettoyÃ©:\n",
            "   'can't believe how terrible this is i'm extremely disappointed ğŸ˜ worst experience ever!'\n",
            "\n",
            "ğŸ”¤ Tokens (14) :\n",
            "   [\"can't\", 'believe', 'how', 'terrible', 'this', 'is', \"i'm\", 'extremely', 'disappointed', 'ğŸ˜', 'worst', 'experience', 'ever', '!']\n",
            "\n",
            "ğŸš« Sans stopwords (10) :\n",
            "   [\"can't\", 'believe', 'terrible', 'extremely', 'disappointed', 'ğŸ˜', 'worst', 'experience', 'ever', '!']\n",
            "\n",
            "ğŸ”„ LemmatisÃ© (11) :\n",
            "   ['can', \"'t\", 'believe', 'terrible', 'extremely', 'disapointed', 'ğŸ˜', 'worst', 'experience', 'ever', '!']\n",
            "\n",
            "================================================================================\n",
            "ğŸ“ EXEMPLE 3\n",
            "================================================================================\n",
            "ğŸ”¸ Original:\n",
            "   <p>This ChatGPT update is @amazing #AI https://example.com BUT I don't think it's perfect yet...</p>\n",
            "\n",
            "ğŸ§¹ NettoyÃ©:\n",
            "   'this chatgpt update is BUT i don't think it's perfect yet'\n",
            "\n",
            "ğŸ”¤ Tokens (11) :\n",
            "   ['this', 'chatgpt', 'update', 'is', 'BUT', 'i', \"don't\", 'think', \"it's\", 'perfect', 'yet']\n",
            "\n",
            "ğŸš« Sans stopwords (7) :\n",
            "   ['chatgpt', 'update', 'BUT', 'i', 'think', 'perfect', 'yet']\n",
            "\n",
            "ğŸ”„ LemmatisÃ© (7) :\n",
            "   ['chatgpt', 'update', 'BUT', 'i', 'think', 'perfect', 'yet']\n",
            "\n",
            "================================================================================\n",
            "ğŸ“ EXEMPLE 4\n",
            "================================================================================\n",
            "ğŸ”¸ Original:\n",
            "   Nooooo way! This is incredible!!! I absolutely looove it ğŸ’• 10/10 would recommend!\n",
            "\n",
            "ğŸ§¹ NettoyÃ©:\n",
            "   'nooooo way! this is incredible!!! i absolutely looove it ğŸ’• would recommend!'\n",
            "\n",
            "ğŸ”¤ Tokens (17) :\n",
            "   ['noo', 'way', '!', 'this', 'is', 'incredible', '!', '!', '!', 'i', 'absolutely', 'loove', 'it', 'ğŸ’•', 'would', 'recommend', '!']\n",
            "\n",
            "ğŸš« Sans stopwords (14) :\n",
            "   ['noo', 'way', '!', 'incredible', '!', '!', '!', 'i', 'absolutely', 'loove', 'ğŸ’•', 'would', 'recommend', '!']\n",
            "\n",
            "ğŸ”„ LemmatisÃ© (14) :\n",
            "   ['noo', 'way', '!', 'incredible', '!', '!', '!', 'i', 'absolutely', 'love', 'ğŸ’•', 'would', 'recomend', '!']\n",
            "\n",
            "================================================================================\n",
            "ğŸ“ EXEMPLE 5\n",
            "================================================================================\n",
            "ğŸ”¸ Original:\n",
            "   It's quite good, but I've seen better products in 2024. Not bad though, just not outstanding.\n",
            "\n",
            "ğŸ§¹ NettoyÃ©:\n",
            "   'it's quite good but i've seen better products in not bad though just not outstanding'\n",
            "\n",
            "ğŸ”¤ Tokens (15) :\n",
            "   [\"it's\", 'quite', 'good', 'but', \"i've\", 'seen', 'better', 'products', 'in', 'not', 'bad', 'though', 'just', 'not', 'outstanding']\n",
            "\n",
            "ğŸš« Sans stopwords (12) :\n",
            "   ['quite', 'good', 'but', 'seen', 'better', 'products', 'not', 'bad', 'though', 'just', 'not', 'outstanding']\n",
            "\n",
            "ğŸ”„ LemmatisÃ© (12) :\n",
            "   ['quite', 'god', 'but', 'sen', 'better', 'product', 'not', 'bad', 'though', 'just', 'not', 'outstanding']\n",
            "\n",
            "================================================================================\n",
            "ğŸ“ EXEMPLE 6\n",
            "================================================================================\n",
            "ğŸ”¸ Original:\n",
            "   OMG this is HORRIBLE!!! Won't buy again, totally disgusting and revolting ğŸ¤®\n",
            "\n",
            "ğŸ§¹ NettoyÃ©:\n",
            "   'OMG this is horrible!!! won't buy again totally disgusting and revolting ğŸ¤®'\n",
            "\n",
            "ğŸ”¤ Tokens (15) :\n",
            "   ['OMG', 'this', 'is', 'horrible', '!', '!', '!', \"won't\", 'buy', 'again', 'totally', 'disgusting', 'and', 'revolting', 'ğŸ¤®']\n",
            "\n",
            "ğŸš« Sans stopwords (10) :\n",
            "   ['OMG', 'horrible', '!', '!', '!', 'buy', 'totally', 'disgusting', 'revolting', 'ğŸ¤®']\n",
            "\n",
            "ğŸ”„ LemmatisÃ© (10) :\n",
            "   ['OMG', 'horrible', '!', '!', '!', 'buy', 'totally', 'disgusting', 'revolting', 'ğŸ¤®']\n",
            "\n",
            "================================================================================\n",
            "ğŸ“ EXEMPLE 7\n",
            "================================================================================\n",
            "ğŸ”¸ Original:\n",
            "   I really, really love this! It's so much more efficient than the old version. Fantastic work!\n",
            "\n",
            "ğŸ§¹ NettoyÃ©:\n",
            "   'i really really love this! it's so much more efficient than the old version fantastic work!'\n",
            "\n",
            "ğŸ”¤ Tokens (18) :\n",
            "   ['i', 'really', 'really', 'love', 'this', '!', \"it's\", 'so', 'much', 'more', 'efficient', 'than', 'the', 'old', 'version', 'fantastic', 'work', '!']\n",
            "\n",
            "ğŸš« Sans stopwords (14) :\n",
            "   ['i', 'really', 'really', 'love', '!', 'so', 'much', 'more', 'efficient', 'old', 'version', 'fantastic', 'work', '!']\n",
            "\n",
            "ğŸ”„ LemmatisÃ© (14) :\n",
            "   ['i', 'realy', 'realy', 'love', '!', 'so', 'much', 'more', 'eficient', 'old', 'version', 'fantastic', 'work', '!']\n"
          ]
        }
      ],
      "source": [
        "def display_results(results, example_num):\n",
        "\t\"\"\"\n",
        "\tAffiche les rÃ©sultats de faÃ§on lisible.\n",
        "\t\"\"\"\n",
        "\tprint(f\"\\n{'='*80}\")\n",
        "\tprint(f\"ğŸ“ EXEMPLE {example_num}\")\n",
        "\tprint(f\"{'='*80}\")\n",
        "\t\n",
        "\tprint(f\"ğŸ”¸ Original:\")\n",
        "\tprint(f\"   {results['original']}\")\n",
        "\t\n",
        "\tprint(f\"\\nğŸ§¹ NettoyÃ©:\")\n",
        "\tprint(f\"   '{results['cleaned']}'\")\n",
        "\t\n",
        "\tprint(f\"\\nğŸ”¤ Tokens ({len(results['tokens'])}) :\")\n",
        "\tprint(f\"   {results['tokens']}\")\n",
        "\t\n",
        "\tprint(f\"\\nğŸš« Sans stopwords ({len(results['without_stopwords'])}) :\")\n",
        "\tprint(f\"   {results['without_stopwords']}\")\n",
        "\t\n",
        "\tprint(f\"\\nğŸ”„ LemmatisÃ© ({len(results['lemmatized'])}) :\")\n",
        "\tprint(f\"   {results['lemmatized']}\")\n",
        "\n",
        "# Test de tous les exemples\n",
        "for i, text in enumerate(test_texts, 1):\n",
        "\tresults = process_text_light(text)\n",
        "\tdisplay_results(results, i)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
