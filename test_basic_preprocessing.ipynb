{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test du Pipeline Basic de Preprocessing\n",
        "\n",
        "Ce notebook teste la version \"basic\" du pipeline de preprocessing avec les classes standard.\n",
        "\n",
        "## ğŸ“‹ Pipeline testÃ© :\n",
        "1. **Nettoyage** (`TextCleaner` basic)\n",
        "2. **Tokenisation** (`TextTokenizer` amÃ©liorÃ©)\n",
        "3. **Retrait des stopwords** (`StopwordRemover` basic) \n",
        "4. **Lemmatisation** (`TextLemmatizer` basic)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports des classes basic\n",
        "import sys\n",
        "sys.path.append('preprocessing')\n",
        "sys.path.append('preprocessing/basic')\n",
        "\n",
        "from preprocessing.basic.text_cleaner import TextCleaner\n",
        "from preprocessing.text_tokenizer import TextTokenizer\n",
        "from preprocessing.basic.stopword_remover import StopwordRemover\n",
        "from preprocessing.basic.text_lemmatizer import TextLemmatizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration NLTK\n",
        "import nltk\n",
        "import os\n",
        "\n",
        "nltk_dir = 'nltk_data'\n",
        "nltk.data.path.append(os.path.abspath(nltk_dir))\n",
        "\n",
        "# DÃ©commentez si premier run\n",
        "# nltk.download('punkt_tab', download_dir=nltk_dir)\n",
        "# nltk.download('stopwords', download_dir=nltk_dir)\n",
        "# nltk.download('wordnet', download_dir=nltk_dir)\n",
        "# nltk.download('omw-1.4', download_dir=nltk_dir)\n",
        "# nltk.download('averaged_perceptron_tagger_eng', download_dir=nltk_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Toutes les classes basic sont initialisÃ©es !\n"
          ]
        }
      ],
      "source": [
        "# Initialisation des classes\n",
        "text_cleaner = TextCleaner()\n",
        "tokenizer = TextTokenizer(nltk_dir=nltk_dir)\n",
        "stopword_remover = StopwordRemover()\n",
        "lemmatizer = TextLemmatizer()\n",
        "\n",
        "print(\"âœ… Toutes les classes basic sont initialisÃ©es !\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ§ª Exemples de Test\n",
        "\n",
        "Nous allons tester les mÃªmes exemples avec le pipeline basic :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“ 7 exemples de test prÃ©parÃ©s\n"
          ]
        }
      ],
      "source": [
        "# Exemples de textes avec diffÃ©rents dÃ©fis\n",
        "test_texts = [\n",
        "\t\"I'm soooo HAPPY!!! This is absolutely AMAZING ğŸ˜ Much better than before!!!\",\n",
        "\t\n",
        "\t\"Can't believe how terrible this is... I'm extremely disappointed ğŸ˜ Worst experience EVER!\",\n",
        "\t\n",
        "\t\"<p>This ChatGPT update is @amazing #AI https://example.com BUT I don't think it's perfect yet...</p>\",\n",
        "\t\n",
        "\t\"Nooooo way! This is incredible!!! I absolutely looove it ğŸ’• 10/10 would recommend!\",\n",
        "\t\n",
        "\t\"It's quite good, but I've seen better products in 2024. Not bad though, just not outstanding.\",\n",
        "\t\n",
        "\t\"OMG this is HORRIBLE!!! Won't buy again, totally disgusting and revolting ğŸ¤®\",\n",
        "\t\n",
        "\t\"I really, really love this! It's so much more efficient than the old version. Fantastic work!\"\n",
        "]\n",
        "\n",
        "print(f\"ğŸ“ {len(test_texts)} exemples de test prÃ©parÃ©s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”„ Pipeline Basic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_text_basic(text):\n",
        "\t\"\"\"\n",
        "\tApplique le pipeline basic complet sur un texte.\n",
        "\t\n",
        "\tArgs:\n",
        "\t\ttext (str): Texte Ã  traiter\n",
        "\t\t\n",
        "\tReturns:\n",
        "\t\tdict: RÃ©sultats de chaque Ã©tape\n",
        "\t\"\"\"\n",
        "\tresults = {\n",
        "\t\t'original': text,\n",
        "\t\t'cleaned': '',\n",
        "\t\t'tokens': [],\n",
        "\t\t'without_stopwords': [],\n",
        "\t\t'lemmatized': []\n",
        "\t}\n",
        "\t\n",
        "\t# Ã‰tape 1: Nettoyage\n",
        "\tresults['cleaned'] = text_cleaner.clean_text(text)\n",
        "\t\n",
        "\t# Ã‰tape 2: Tokenisation\n",
        "\tresults['tokens'] = tokenizer.tokenize(results['cleaned'])\n",
        "\t\n",
        "\t# Ã‰tape 3: Retrait des stopwords\n",
        "\tresults['without_stopwords'] = stopword_remover.remove_stopwords(results['tokens'])\n",
        "\t\n",
        "\t# Ã‰tape 4: Lemmatisation\n",
        "\tresults['lemmatized'] = lemmatizer.lemmatize(results['without_stopwords'])\n",
        "\t\n",
        "\treturn results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š RÃ©sultats du Pipeline Basic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "ğŸ“ EXEMPLE 1\n",
            "============================================================\n",
            "ğŸ”¸ Original:\n",
            "   I'm soooo HAPPY!!! This is absolutely AMAZING ğŸ˜ Much better than before!!!\n",
            "\n",
            "ğŸ§¹ NettoyÃ©:\n",
            "   'im soooo happy this is absolutely amazing much better than before'\n",
            "\n",
            "ğŸ”¤ Tokens (11) :\n",
            "   ['im', 'soo', 'happy', 'this', 'is', 'absolutely', 'amazing', 'much', 'better', 'than', 'before']\n",
            "\n",
            "ğŸš« Sans stopwords (7) :\n",
            "   ['im', 'soo', 'happy', 'absolutely', 'amazing', 'much', 'better']\n",
            "\n",
            "ğŸ”„ LemmatisÃ© (7) :\n",
            "   ['im', 'soo', 'happy', 'absolutely', 'amaze', 'much', 'well']\n",
            "\n",
            "============================================================\n",
            "ğŸ“ EXEMPLE 2\n",
            "============================================================\n",
            "ğŸ”¸ Original:\n",
            "   Can't believe how terrible this is... I'm extremely disappointed ğŸ˜ Worst experience EVER!\n",
            "\n",
            "ğŸ§¹ NettoyÃ©:\n",
            "   'cant believe how terrible this is im extremely disappointed worst experience ever'\n",
            "\n",
            "ğŸ”¤ Tokens (12) :\n",
            "   ['cant', 'believe', 'how', 'terrible', 'this', 'is', 'im', 'extremely', 'disappointed', 'worst', 'experience', 'ever']\n",
            "\n",
            "ğŸš« Sans stopwords (9) :\n",
            "   ['cant', 'believe', 'terrible', 'im', 'extremely', 'disappointed', 'worst', 'experience', 'ever']\n",
            "\n",
            "ğŸ”„ LemmatisÃ© (9) :\n",
            "   ['cant', 'believe', 'terrible', 'im', 'extremely', 'disappointed', 'bad', 'experience', 'ever']\n",
            "\n",
            "============================================================\n",
            "ğŸ“ EXEMPLE 3\n",
            "============================================================\n",
            "ğŸ”¸ Original:\n",
            "   <p>This ChatGPT update is @amazing #AI https://example.com BUT I don't think it's perfect yet...</p>\n",
            "\n",
            "ğŸ§¹ NettoyÃ©:\n",
            "   'this chatgpt update is but i dont think its perfect yet'\n",
            "\n",
            "ğŸ”¤ Tokens (11) :\n",
            "   ['this', 'chatgpt', 'update', 'is', 'but', 'i', 'dont', 'think', 'its', 'perfect', 'yet']\n",
            "\n",
            "ğŸš« Sans stopwords (6) :\n",
            "   ['chatgpt', 'update', 'dont', 'think', 'perfect', 'yet']\n",
            "\n",
            "ğŸ”„ LemmatisÃ© (6) :\n",
            "   ['chatgpt', 'update', 'dont', 'think', 'perfect', 'yet']\n",
            "\n",
            "============================================================\n",
            "ğŸ“ EXEMPLE 4\n",
            "============================================================\n",
            "ğŸ”¸ Original:\n",
            "   Nooooo way! This is incredible!!! I absolutely looove it ğŸ’• 10/10 would recommend!\n",
            "\n",
            "ğŸ§¹ NettoyÃ©:\n",
            "   'nooooo way this is incredible i absolutely looove it would recommend'\n",
            "\n",
            "ğŸ”¤ Tokens (11) :\n",
            "   ['noo', 'way', 'this', 'is', 'incredible', 'i', 'absolutely', 'loove', 'it', 'would', 'recommend']\n",
            "\n",
            "ğŸš« Sans stopwords (7) :\n",
            "   ['noo', 'way', 'incredible', 'absolutely', 'loove', 'would', 'recommend']\n",
            "\n",
            "ğŸ”„ LemmatisÃ© (7) :\n",
            "   ['noo', 'way', 'incredible', 'absolutely', 'loove', 'would', 'recommend']\n",
            "\n",
            "============================================================\n",
            "ğŸ“ EXEMPLE 5\n",
            "============================================================\n",
            "ğŸ”¸ Original:\n",
            "   It's quite good, but I've seen better products in 2024. Not bad though, just not outstanding.\n",
            "\n",
            "ğŸ§¹ NettoyÃ©:\n",
            "   'its quite good but ive seen better products in not bad though just not outstanding'\n",
            "\n",
            "ğŸ”¤ Tokens (15) :\n",
            "   ['its', 'quite', 'good', 'but', 'ive', 'seen', 'better', 'products', 'in', 'not', 'bad', 'though', 'just', 'not', 'outstanding']\n",
            "\n",
            "ğŸš« Sans stopwords (11) :\n",
            "   ['quite', 'good', 'ive', 'seen', 'better', 'products', 'not', 'bad', 'though', 'not', 'outstanding']\n",
            "\n",
            "ğŸ”„ LemmatisÃ© (11) :\n",
            "   ['quite', 'good', 'ive', 'see', 'well', 'product', 'not', 'bad', 'though', 'not', 'outstanding']\n",
            "\n",
            "============================================================\n",
            "ğŸ“ EXEMPLE 6\n",
            "============================================================\n",
            "ğŸ”¸ Original:\n",
            "   OMG this is HORRIBLE!!! Won't buy again, totally disgusting and revolting ğŸ¤®\n",
            "\n",
            "ğŸ§¹ NettoyÃ©:\n",
            "   'omg this is horrible wont buy again totally disgusting and revolting'\n",
            "\n",
            "ğŸ”¤ Tokens (11) :\n",
            "   ['omg', 'this', 'is', 'horrible', 'wont', 'buy', 'again', 'totally', 'disgusting', 'and', 'revolting']\n",
            "\n",
            "ğŸš« Sans stopwords (7) :\n",
            "   ['omg', 'horrible', 'wont', 'buy', 'totally', 'disgusting', 'revolting']\n",
            "\n",
            "ğŸ”„ LemmatisÃ© (7) :\n",
            "   ['omg', 'horrible', 'wont', 'buy', 'totally', 'disgust', 'revolt']\n",
            "\n",
            "============================================================\n",
            "ğŸ“ EXEMPLE 7\n",
            "============================================================\n",
            "ğŸ”¸ Original:\n",
            "   I really, really love this! It's so much more efficient than the old version. Fantastic work!\n",
            "\n",
            "ğŸ§¹ NettoyÃ©:\n",
            "   'i really really love this its so much more efficient than the old version fantastic work'\n",
            "\n",
            "ğŸ”¤ Tokens (16) :\n",
            "   ['i', 'really', 'really', 'love', 'this', 'its', 'so', 'much', 'more', 'efficient', 'than', 'the', 'old', 'version', 'fantastic', 'work']\n",
            "\n",
            "ğŸš« Sans stopwords (9) :\n",
            "   ['really', 'really', 'love', 'much', 'efficient', 'old', 'version', 'fantastic', 'work']\n",
            "\n",
            "ğŸ”„ LemmatisÃ© (9) :\n",
            "   ['really', 'really', 'love', 'much', 'efficient', 'old', 'version', 'fantastic', 'work']\n"
          ]
        }
      ],
      "source": [
        "def display_basic_results(results, example_num):\n",
        "\t\"\"\"\n",
        "\tAffiche les rÃ©sultats de faÃ§on simple et lisible.\n",
        "\t\"\"\"\n",
        "\tprint(f\"\\n{'='*60}\")\n",
        "\tprint(f\"ğŸ“ EXEMPLE {example_num}\")\n",
        "\tprint(f\"{'='*60}\")\n",
        "\t\n",
        "\tprint(f\"ğŸ”¸ Original:\")\n",
        "\tprint(f\"   {results['original']}\")\n",
        "\t\n",
        "\tprint(f\"\\nğŸ§¹ NettoyÃ©:\")\n",
        "\tprint(f\"   '{results['cleaned']}'\")\n",
        "\t\n",
        "\tprint(f\"\\nğŸ”¤ Tokens ({len(results['tokens'])}) :\")\n",
        "\tprint(f\"   {results['tokens']}\")\n",
        "\t\n",
        "\tprint(f\"\\nğŸš« Sans stopwords ({len(results['without_stopwords'])}) :\")\n",
        "\tprint(f\"   {results['without_stopwords']}\")\n",
        "\t\n",
        "\tprint(f\"\\nğŸ”„ LemmatisÃ© ({len(results['lemmatized'])}) :\")\n",
        "\tprint(f\"   {results['lemmatized']}\")\n",
        "\n",
        "# Test de tous les exemples avec le pipeline basic\n",
        "for i, text in enumerate(test_texts, 1):\n",
        "\tresults = process_text_basic(text)\n",
        "\tdisplay_basic_results(results, i)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
